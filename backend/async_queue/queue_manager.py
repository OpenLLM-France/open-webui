import os
from redis.asyncio import Redis
from redis import Redis as SyncRedis
from celery import Celery
import json
import asyncio
import time
import logging
from typing import Dict, Any, List
import datetime
from .celery_app import celery_app  # Assurez-vous que celery_app.py existe dans le m√™me dossier

# Configuration de Celery
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))

celery = Celery(
    'queue_manager',
    broker_url=f'redis://{REDIS_HOST}:{REDIS_PORT}',
    result_backend=f'redis://{REDIS_HOST}:{REDIS_PORT}',
)

logger = logging.getLogger('test_logger')
logger.setLevel(logging.DEBUG)

# R√©cup√©ration des variables d'environnement Redis
REDIS_DB = int(os.getenv('REDIS_DB', 0))
DEBUG = os.getenv('DEBUG', 'false')
# Configuration de base
celery.conf.update(
    broker_url=f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}',
    result_backend=f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}',
    broker_connection_retry=True,  # Activer les retry
    broker_connection_max_retries=None,  # Retry ind√©finiment
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    worker_max_tasks_per_child=1000,
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    task_track_started=True
)

# Forcer le mode eager si en test
if os.environ.get('TESTING') == 'true':
    logger.info("Mode TEST d√©tect√©")
    celery.conf.update(
        worker_prefetch_multiplier=1,
        task_acks_late=False,
        task_track_started=True,
        task_send_sent_event=True,
        task_remote_tracebacks=True,
        task_store_errors_even_if_ignored=True,
        task_ignore_result=False,
        worker_log_level='DEBUG'  # Activer les logs de debug
    )
    logger.info(f"Configuration Celery en mode TEST")

logger.info(f"Mode Celery au d√©marrage: EAGER={celery.conf.task_always_eager}")

class QueueManager:
    """Gestionnaire de file d'attente avec Redis."""

    def __init__(self, redis: Redis):
        """Initialise le gestionnaire de file d'attente.

        Args:
            redis (Redis): Le client Redis √† utiliser
        """
        self.redis = redis
        self.max_active_users = 10  # Valeur par d√©faut
        self._slot_check_task = None
        self._stop_slot_check = False

        self._slot_check_interval = 2.0  # Intervalle de v√©rification des slots en secondes
        self._timer_tasks = {}  # Pour stocker les t√¢ches de timer par user_id
        self.connection_manager = None
        self.logger = logging.getLogger(__name__)
        
        # Configurations
        self.max_active_users = int(os.getenv('MAX_ACTIVE_USERS', 2))
        self.draft_duration = 300  # 5 minutes
        self.session_duration = 1200 # 20 minutes

    def set_connection_manager(self, manager):
        """D√©finit le gestionnaire de connexions WebSocket."""
        self.connection_manager = manager

    def update_draft_duration(self, duration: int):
        """Met √† jour la dur√©e du draft."""
        self.draft_duration = duration
    def update_session_duration(self, duration: int):
        """Met √† jour la dur√©e de la session."""
        self.session_duration = duration

    async def _send_timer_update(self, user_id: str, timer_type: str, ttl: int):
        """Envoie une mise √† jour de timer via WebSocket."""
        if self.connection_manager:
            await self.connection_manager.send_timer_update(user_id, {
                "timer_type": timer_type,
                "ttl": ttl,
                "updates_left": 3  # Pour compatibilit√© avec l'ancien format
            })

    async def _verify_queue_state(self, user_id: str, expected_states, message: str = "") -> bool:
        """V√©rifie l'√©tat de la file d'attente pour un utilisateur."""
        try:
            logger.debug(f"V√©rification de l'√©tat pour {user_id} avec attentes: {expected_states}")
            logger.debug(f"Message: {message}")
            # Convertir en liste si c'est un dictionnaire unique
            if isinstance(expected_states, dict):
                expected_states = [expected_states]
                
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.sismember('queued_users', user_id)  # Utiliser queued_users pour v√©rifier la pr√©sence
                pipe.sismember('queued_users', user_id)  # in_waiting est le m√™me que in_queue
                pipe.sismember('draft_users', user_id)
                pipe.sismember('active_users', user_id)
                pipe.sismember('accounts_queue', user_id)
                results = await pipe.execute()
                
                actual_state = {
                    'in_queue': bool(results[0]),
                    'in_waiting': bool(results[1]),  # M√™me √©tat que in_queue
                    'in_draft': bool(results[2]),
                    'in_active': bool(results[3]),
                    'in_accounts_queue': bool(results[4])
                }
                
                logger.debug(f"√âtat actuel pour {user_id}: {actual_state}")
                
                # V√©rifier si l'√©tat actuel correspond √† l'un des √©tats attendus
                for expected_state in expected_states:
                    matches = True
                    for key, expected in expected_state.items():
                        if isinstance(expected, (list, tuple)):
                            if actual_state[key] not in expected:
                                matches = False
                                break
                        elif actual_state[key] != expected:
                            matches = False
                            break
                    
                    if matches:
                        logger.debug(f"√âtat v√©rifi√© avec succ√®s pour {user_id} (correspond √† {expected_state})")
                        return True
                
                # Si aucun √©tat attendu ne correspond
                logger.warning(f"√âtat invalide pour {user_id} - actuel={actual_state}, attendu l'un de {expected_states}")
                return False
                
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification pour {user_id}: {str(e)}")
            return False

    async def _check_slots_after_add(self):
        """V√©rifie les slots disponibles de mani√®re asynchrone."""
        try:
            # R√©cup√©rer d'abord toute la waiting queue
            waiting_queue = await self.redis.lrange('waiting_queue', 0, -1)
            if not waiting_queue:
                return True

            # V√©rifier les slots disponibles
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.scard('active_users')
                pipe.scard('draft_users')
                results = await pipe.execute()
                
            active_count, draft_count = results
            available_slots = self.max_active_users - (active_count + draft_count)

            if available_slots > 0:
                # Prendre seulement le nombre d'utilisateurs n√©cessaire
                users_to_check = waiting_queue[:available_slots]
                
                # V√©rifier les utilisateurs en attente en une seule fois
                async with self.redis.pipeline(transaction=True) as pipe:
                    for user_id in users_to_check:
                        pipe.sismember('queued_users', user_id)
                    is_queued_results = await pipe.execute()
                
                # Offrir des slots aux utilisateurs √©ligibles
                for i, is_queued in enumerate(is_queued_results):
                    if is_queued:
                        await self.offer_slot(users_to_check[i])
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la v√©rification des slots : {str(e)}")
            return False

    async def start_slot_checker(self, check_interval: float = None):
        """D√©marre le v√©rificateur de slots."""
        if self._slot_check_task is not None:
            logger.warning("Le v√©rificateur de slots est d√©j√† en cours d'ex√©cution")
            return

        if check_interval is not None:
            self._slot_check_interval = check_interval
            
        self._stop_slot_check = False
        self._slot_check_task = asyncio.create_task(self._slot_check_loop())
        logger.info(f"V√©rificateur de slots d√©marr√© (intervalle: {self._slot_check_interval}s)")

    async def _slot_check_loop(self):
        """Boucle de v√©rification des slots."""
        try:
            while not self._stop_slot_check:
                await self.check_available_slots()
                await asyncio.sleep(self._slot_check_interval)
        except asyncio.CancelledError:
            logger.info("V√©rificateur de slots arr√™t√©")
        except Exception as e:
            logger.error(f"Erreur dans le v√©rificateur de slots: {str(e)}")
            self._slot_check_task = None

    async def stop_slot_checker(self):
        """Arr√™te la v√©rification p√©riodique des slots."""
        if self._slot_check_task is not None:
            self._stop_slot_check = True
            await self._slot_check_task
            self._slot_check_task = None

    async def add_to_queue(self, user_id: str, check_slots: bool = True) -> Dict:
        """Ajoute un utilisateur √† la file d'attente principale."""
        try:
            logger.info(f"üîÑ Tentative d'ajout de l'utilisateur {user_id}")
            
            # Obtenir le statut actuel
            last_status = await self.get_user_status(user_id, check_slots=check_slots)
            logger.info(f"üìä Statut actuel pour {user_id}: {last_status}")
            
            # Si l'utilisateur n'existe pas dans Redis
            current_state = await self._get_current_state(user_id)
            logger.info(f"üîç √âtat actuel pour {user_id}: {current_state}")
            
            if await self._verify_queue_state(user_id, {
                'in_queue': False,
                'in_waiting': False,
                'in_draft': False,
                'in_active': False,
                'in_accounts_queue': [False, True]
            }):
                logger.debug(f"‚ú® Nouvel utilisateur d√©tect√©: {user_id}")
                last_status = {"status": None, "position": None}
            
            # Si l'utilisateur est d√©connect√© ou n'a pas de statut
            if last_status["status"] in [None, 'disconnected']:
                logger.info(f"‚û°Ô∏è Ajout √† la file d'attente pour {user_id} avec statut {last_status['status']}")
                async with self.redis.pipeline(transaction=True) as pipe:
                    logger.debug(f"üîí D√©but transaction Redis pour {user_id}")
                    # Ajouter √† la file d'attente et √† accounts_queue
                    pipe.rpush('waiting_queue', user_id)  # Utiliser rpush pour garder l'ordre FIFO
                    pipe.sadd('queued_users', user_id)
                    pipe.sadd('accounts_queue', user_id)
                    pipe.llen('waiting_queue')  # Utiliser llen pour avoir la position
                    results = await pipe.execute()
                    logger.info(f"üìù R√©sultats de la transaction Redis pour {user_id}: {results}")
                    position = results[-1]
                    logger.debug(f"üìç Position pour {user_id}: {position}")
                    
                    # V√©rification imm√©diate post-transaction
                    is_queued = await self.redis.sismember('queued_users', user_id)
                    is_in_waiting = await self.redis.lpos('waiting_queue', user_id) is not None
                    logger.info(f"‚úÖ V√©rification post-transaction pour {user_id}: queued={is_queued}, in_waiting={is_in_waiting}")

                    if not (is_queued and is_in_waiting):
                        logger.error(f"‚ùå √âchec de l'ajout √† la file d'attente pour {user_id}")
                        raise Exception("√âchec de l'ajout √† la file d'attente")
                    
                    # V√©rifier l'√©tat apr√®s l'ajout
                    new_state = await self._get_current_state(user_id)
                    logger.info(f"üîÑ Nouvel √©tat pour {user_id}: {new_state}")
                    
                    expected_states = [
                        # √âtat 1: En attente dans la file
                        {
                            'in_queue': True,
                            'in_waiting': True,
                            'in_draft': False,
                            'in_active': False,
                            'in_accounts_queue': [True, False]
                        }
                    ]
                    
                    if not await self._verify_queue_state(user_id, expected_states):
                        logger.error(f"‚ùå √âtat incoh√©rent apr√®s l'ajout pour {user_id}")
                        logger.error(f"√âtat attendu: {expected_states}")
                        logger.error(f"√âtat actuel: {new_state}")
                        raise Exception("√âtat incoh√©rent apr√®s l'ajout √† la file")
                    
                    # V√©rifier les slots disponibles si demand√©
                    if check_slots:
                        await self._check_slots_after_add()
                    # Afficher l'√©tat de la liste d'attente et de la draft
                    async with self.redis.pipeline(transaction=True) as pipe:
                        pipe.llen('waiting_queue')  # Taille de la liste d'attente
                        pipe.scard('draft_users')  # Nombre d'utilisateurs en draft
                        results = await pipe.execute()
                        waiting_queue_size = results[0]
                        draft_users_count = results[1]
                        logger.info(f"√âtat actuel: Liste d'attente - {waiting_queue_size} utilisateurs, Draft - {draft_users_count} utilisateurs")
                    # Obtenir le nouveau statut apr√®s l'ajout et la v√©rification des slots
                    new_status = await self.get_user_status(user_id, check_slots=check_slots)
                    
                    # V√©rifier si l'utilisateur est pass√© en draft
                    is_draft = await self.redis.sismember('draft_users', user_id)
                    if is_draft:
                        new_status["status"] = "draft"
                        position = -1
                    else:
                        # Retourner la position r√©elle dans la file
                        waiting_pos = await self.redis.lpos('waiting_queue', user_id)
                        if waiting_pos is not None:
                            position = waiting_pos + 1
                        else:
                            position = new_status.get("position", None)
                    
                    logger.info(f"‚úÖ Ajout r√©ussi pour {user_id} - Status: {new_status['status']}, Position: {position}")
                    return {
                        "last_status": last_status["status"],
                        "last_position": last_status.get("position", None),
                        "commit_status": new_status["status"],
                        "commit_position": position
                    }
            
            # Pour tous les autres cas, retourner le statut actuel
            logger.info(f"‚ÑπÔ∏è Retour du statut actuel pour {user_id}: {last_status}")
            return {
                "last_status": last_status["status"],
                "last_position": last_status.get("position", None),
                "commit_status": last_status["status"],
                "commit_position": last_status.get("position", None)
            }
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'ajout √† la file pour {user_id}: {str(e)}")
            logger.error(f"√âtat actuel lors de l'erreur: {await self._get_current_state(user_id)}")
            
            # Nettoyage en cas d'erreur
            async with self.redis.pipeline(transaction=True) as pipe:
                logger.debug(f"üßπ Nettoyage apr√®s erreur pour {user_id}")
                pipe.lrem('waiting_queue', 0, user_id)  # Utiliser lrem pour la liste
                pipe.srem('queued_users', user_id)
                await pipe.execute()
                
            return {
                "last_status": None,
                "last_position": None,
                "commit_status": None,
                "commit_position": None
            }

    async def _get_current_state(self, user_id: str) -> Dict[str, bool]:
        """R√©cup√®re l'√©tat actuel d'un utilisateur dans toutes les files."""
        async with self.redis.pipeline(transaction=True) as pipe:
            pipe.sismember('queued_users', user_id)
            pipe.lpos('waiting_queue', user_id)
            pipe.sismember('draft_users', user_id)
            pipe.sismember('active_users', user_id)
            pipe.sismember('accounts_queue', user_id)
            results = await pipe.execute()
            
        return {
            'in_queue': results[0],
            'in_waiting': results[1] is not None,
            'in_draft': results[2],
            'in_active': results[3],
            'in_accounts_queue': results[4]
        }

    async def remove_from_queue(self, user_id: str) -> bool:
        """Retire un utilisateur de la file d'attente."""
        try:
            is_queued = await self.redis.sismember('queued_users', user_id)
            is_draft = await self.redis.sismember('draft_users', user_id)
            is_active = await self.redis.sismember('active_users', user_id)
            
            if is_queued or is_draft or is_active:
                async with self.redis.pipeline(transaction=True) as pipe:
                    if is_queued:
                        pipe.lrem('waiting_queue', 0, user_id)  # Retirer de la liste d'attente
                        pipe.srem('queued_users', user_id)  # Retirer de l'ensemble des utilisateurs en attente
                    if is_draft:
                        pipe.srem('draft_users', user_id)
                        pipe.delete(f'draft:{user_id}')
                    if is_active:
                        pipe.srem('active_users', user_id)
                        pipe.delete(f'session:{user_id}')
                    pipe.publish(f'queue_status:{user_id}', 
                        json.dumps({
                            "status": "disconnected",
                            "position": None,
                            "timestamp": int(time.time())
                        })
                    )
                    await pipe.execute()
                    
                    # V√©rifier l'√©tat apr√®s suppression
                    expected_state = {
                        'in_queue': False,
                        'in_waiting': False,
                        'in_draft': False,
                        'in_active': False,
                        'in_accounts_queue': True  # L'utilisateur doit rester dans accounts_queue
                    }
                    logger.debug(f"V√©rification de l'√©tat apr√®s suppression pour {user_id}: {expected_state}")
                    if not await self._verify_queue_state(user_id, expected_state, message="iciiiiii"):
                        raise Exception("√âtat incoh√©rent apr√®s la suppression")
                    
                    # V√©rifier les slots disponibles
                    await self._check_slots_after_add()
                    
                return True
            return False
        except Exception as e:
            print(f"Erreur lors de la suppression : {str(e)}")
            return False

    async def check_available_slots(self):
        """V√©rifie et attribue les slots disponibles."""
        try:
            # V√©rifier d'abord les slots disponibles
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.multi()
                pipe.scard('active_users')
                pipe.scard('draft_users')
                results = await pipe.execute()
                
                active_count, draft_count = results
                available_slots = self.max_active_users - (active_count + draft_count)
            
            logger.debug(f"Slots disponibles: {available_slots} (actifs: {active_count}, draft: {draft_count})")
            
            if available_slots <= 0:
                logger.info("‚ÑπÔ∏è Plus aucun slot disponible")
                return False

            # R√©cup√©rer et traiter les utilisateurs un par un
            while available_slots > 0:
                # V√©rifier l'√©ligibilit√© et retirer l'utilisateur de mani√®re atomique
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()
                    pipe.lindex('waiting_queue', 0)  # Regarder le premier sans le retirer
                    results = await pipe.execute()
                    
                user_id = results[0]
                if not user_id:
                    logger.debug("Plus d'utilisateurs en attente")
                    break
                
                logger.debug(f"Traitement de l'utilisateur {user_id}")
                
                # V√©rifier l'√©ligibilit√©
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()
                    pipe.sismember('queued_users', user_id)
                    pipe.sismember('active_users', user_id)
                    pipe.sismember('draft_users', user_id)
                    pipe.lpos('waiting_queue', user_id)  # V√©rifier la position
                    results = await pipe.execute()
                
                is_queued, is_active, is_draft, waiting_pos = results
                logger.debug(f"√âtat de {user_id} - queued: {is_queued}, active: {is_active}, draft: {is_draft}, pos: {waiting_pos}")
                
                if not is_queued or is_active or is_draft or waiting_pos is None:
                    logger.warning(f"Utilisateur {user_id} non √©ligible, nettoyage...")
                    # Nettoyer l'√©tat incoh√©rent
                    async with self.redis.pipeline(transaction=True) as pipe:
                        pipe.multi()
                        pipe.lrem('waiting_queue', 0, user_id)  # Retirer de la file
                        pipe.srem('queued_users', user_id)  # Retirer des utilisateurs en queue
                        await pipe.execute()
                    continue

                # Tenter d'offrir un slot
                if await self.offer_slot(user_id):
                    available_slots -= 1
                    logger.info(f"‚úÖ Slot offert √† {user_id}")
                else:
                    logger.warning(f"‚ùå √âchec de l'offre de slot √† {user_id}")
                    # L'utilisateur sera remis en file par offer_slot

            return available_slots > 0

        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification des slots: {str(e)}")
            return False

    async def offer_slot(self, user_id: str, max_retries: int = 3) -> bool:
        """Offre un slot √† un utilisateur."""
        retry_count = 0
        while retry_count < max_retries:
            try:
                logger.debug(f"Tentative {retry_count + 1}/{max_retries} d'offre de slot √† {user_id}")
                
                # V√©rifier l'√©tat actuel
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()  # D√©marrer la transaction AVANT les commandes
                    pipe.sismember('queued_users', user_id)
                    pipe.sismember('active_users', user_id)
                    pipe.sismember('draft_users', user_id)
                    pipe.lpos('waiting_queue', user_id)
                    results = await pipe.execute()
                
                is_queued, is_active, is_draft, waiting_pos = results
                logger.debug(f"√âtat actuel de {user_id} - queued: {is_queued}, active: {is_active}, draft: {is_draft}, waiting_pos: {waiting_pos}")
                
                if not is_queued or is_active or is_draft:
                    logger.warning(f"√âtat invalide pour {user_id} - queued: {is_queued}, active: {is_active}, draft: {is_draft}")
                    return False
                
                # V√©rifier les slots disponibles
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()  # D√©marrer la transaction AVANT les commandes
                    pipe.scard('active_users')
                    pipe.scard('draft_users')
                    results = await pipe.execute()
                    
                active_count, draft_count = results
                if active_count + draft_count >= self.max_active_users:
                    logger.warning(f"Plus de slots disponibles - actifs: {active_count}, draft: {draft_count}")
                    return False

                # Effectuer la transition atomique
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()  # D√©marrer la transaction AVANT les commandes
                    pipe.srem('queued_users', user_id)
                    pipe.sadd('draft_users', user_id)
                    pipe.setex(f'draft:{user_id}', self.draft_duration, '1')
                    pipe.lrem('waiting_queue', 0, user_id)  # Retirer de la waiting_queue
                    results = await pipe.execute()
                    
                    if not all(results):
                        logger.error(f"√âchec de la transition pour {user_id} - r√©sultats: {results}")
                        return False
                    
                    logger.debug(f"Transition r√©ussie pour {user_id}")
                
                # V√©rifier l'√©tat final
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.multi()  # D√©marrer la transaction AVANT les commandes
                    pipe.sismember('queued_users', user_id)
                    pipe.sismember('draft_users', user_id)
                    pipe.exists(f'draft:{user_id}')
                    pipe.lpos('waiting_queue', user_id)
                    results = await pipe.execute()
                
                final_queued, final_draft, has_draft, final_waiting = results
                logger.debug(f"√âtat final de {user_id} - queued: {final_queued}, draft: {final_draft}, has_draft: {has_draft}, waiting: {final_waiting}")
                
                if not final_draft or final_queued or not has_draft or final_waiting is not None:
                    logger.error(f"√âtat final invalide pour {user_id}")
                    return False

                # Publier la notification
                status_info = {
                    "status": "draft",
                    "position": -1,
                    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                await self.redis.publish(f'queue_status:{user_id}', json.dumps(status_info))
                
                logger.info(f"‚úÖ Slot offert avec succ√®s √† {user_id} (timer: {self.draft_duration}s)")
                return True
                
            except Exception as e:
                logger.error(f"‚ùå Tentative {retry_count + 1}/{max_retries} - Erreur lors de l'offre de slot √† {user_id}: {str(e)}")
                retry_count += 1
                if retry_count < max_retries:
                    await asyncio.sleep(0.1 * (retry_count + 1))  # Backoff exponentiel
                continue
        
        # Si on arrive ici, toutes les tentatives ont √©chou√©
        logger.warning(f"‚ùå √âchec de l'offre de slot pour {user_id}, remise en file")
        return False

    async def confirm_connection(self, user_id: str, max_retries: int = 3) -> bool:
        """Confirme la connexion d'un utilisateur."""
        retry_count = 0
        while retry_count < max_retries:
            try:
                # V√©rifier l'√©tat actuel en une seule transaction
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.sismember('draft_users', user_id)
                    pipe.exists(f'draft:{user_id}')
                    pipe.sismember('active_users', user_id)
                    pipe.sismember('queued_users', user_id)
                    pipe.ttl(f'draft:{user_id}')  # R√©cup√©rer le TTL restant
                    results = await pipe.execute()
                    
                    is_draft, has_draft, is_active, is_queued, draft_ttl = results
                    
                    if not (is_draft and has_draft):
                        logger.warning(f"‚ùå L'utilisateur {user_id} n'est pas en √©tat draft (is_draft={is_draft}, has_draft={has_draft})")
                        return False
                        
                    if is_active or is_queued:
                        logger.warning(f"‚ö†Ô∏è √âtat invalide pour {user_id}: d√©j√† actif={is_active} ou en file d'attente={is_queued}")
                        return False

                    if draft_ttl <= 0:
                        logger.warning(f"‚ö†Ô∏è Le timer draft a expir√© pour {user_id} (ttl={draft_ttl})")
                        return False
                    
                    # Effectuer la transition en une seule transaction
                    async with self.redis.pipeline(transaction=True) as pipe:
                        pipe.srem('draft_users', user_id)
                        pipe.sadd('active_users', user_id)
                        pipe.delete(f'draft:{user_id}')
                        pipe.setex(f'session:{user_id}', self.session_duration, '1')
                        # Publier le nouveau timer
                        pipe.publish('user_status', json.dumps({
                            'user_id': user_id,
                            'status': 'active',
                            'timer': {
                                'type': 'session',
                                'duration': self.session_duration,
                                'timestamp': int(time.time())
                            }
                        }))
                        results = await pipe.execute()
                        
                        # V√©rifier que toutes les op√©rations ont r√©ussi
                        if not all(result is not None for result in results[:-1]):  # Ignore le r√©sultat de publish
                            raise Exception("Une ou plusieurs op√©rations ont √©chou√©")
                        
                    logger.info(f"‚úÖ Connexion confirm√©e pour {user_id} (session: {self.session_duration}s)")
                    return {'status': 'active', 'session_duration': self.session_duration, 'message': 'Connexion confirm√©e'}
                    
            except Exception as e:
                retry_count += 1
                logger.error(f"QueueManager : ‚ùå Tentative {retry_count}/{max_retries} - Erreur lors de la confirmation pour {user_id}: {str(e)}")
                if retry_count < max_retries:
                    await asyncio.sleep(0.5 * retry_count)  # Backoff exponentiel
                else:
                    # Nettoyage en cas d'erreur
                    try:
                        async with self.redis.pipeline(transaction=True) as pipe:
                            pipe.srem('active_users', user_id)
                            pipe.srem('draft_users', user_id)
                            pipe.delete(f'session:{user_id}')
                            pipe.delete(f'draft:{user_id}')
                            await pipe.execute()
                    except Exception as cleanup_error:
                        logger.error(f"Erreur lors du nettoyage pour {user_id}: {str(cleanup_error)}")
                    return False

        return False

    async def extend_session(self, user_id: str, max_retries: int = 3) -> bool:
        """Prolonge la session d'un utilisateur actif."""
        retry_count = 0
        while retry_count < max_retries:
            try:
                # V√©rifier l'√©tat en une seule transaction
                async with self.redis.pipeline(transaction=True) as pipe:
                    pipe.sismember('active_users', user_id)
                    pipe.exists(f'session:{user_id}')
                    pipe.ttl(f'session:{user_id}')
                    is_active, has_session, session_ttl = await pipe.execute()
                    
                    if not (is_active and has_session):
                        logger.warning(f"Session invalide pour {user_id}: active={is_active}, has_session={has_session}")
                        return False

                    if session_ttl <= 0:
                        logger.warning(f"Session expir√©e pour {user_id}: ttl={session_ttl}")
                        return False
                    
                    # Prolonger la session
                    async with self.redis.pipeline(transaction=True) as pipe:
                        pipe.setex(f'session:{user_id}', self.session_duration, '1')
                        pipe.publish(f'queue_status:{user_id}', 
                            json.dumps({
                                "status": "extended",
                                "session_duration": self.session_duration,
                                "timestamp": int(time.time())
                            })
                        )
                        results = await pipe.execute()
                        
                        # V√©rifier que l'op√©ration a r√©ussi
                        if not results[0]:
                            raise Exception("√âchec de la prolongation de session")
                    
                    logger.info(f"‚úÖ Session prolong√©e pour {user_id} (nouvelle dur√©e: {self.session_duration}s)")
                    return True
                    
            except Exception as e:
                retry_count += 1
                logger.error(f"‚ùå Tentative {retry_count}/{max_retries} - Erreur lors de la prolongation de session pour {user_id}: {str(e)}")
                if retry_count < max_retries:
                    await asyncio.sleep(0.5 * retry_count)  # Backoff exponentiel
                else:
                    # Nettoyage en cas d'erreur
                    try:
                        async with self.redis.pipeline(transaction=True) as pipe:
                            pipe.srem('active_users', user_id)
                            pipe.delete(f'session:{user_id}')
                            await pipe.execute()
                    except Exception as cleanup_error:
                        logger.error(f"Erreur lors du nettoyage pour {user_id}: {str(cleanup_error)}")
                    return False

        return False

    async def get_user_status(self, user_id: str, check_slots: bool = True, recall=True) -> Dict:
        """R√©cup√®re le statut actuel d'un utilisateur."""
        try:
            # V√©rifier si l'utilisateur existe dans un des √©tats possibles
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.sismember('active_users', user_id)
                pipe.sismember('draft_users', user_id)
                pipe.lpos('waiting_queue', user_id)
                pipe.sismember('queued_users', user_id)
                pipe.sismember('accounts_queue', user_id)  # V√©rifier si l'utilisateur a d√©j√† √©t√© connect√©
                is_active, is_draft, waiting_pos, is_queued, has_account = await pipe.execute()

            # Si l'utilisateur n'existe dans aucun √©tat et n'a jamais √©t√© connect√©, retourner None
            if not any([is_active, is_draft, waiting_pos is not None, is_queued]) and not has_account:
                return {"status": None, "position": None}

            # Si l'utilisateur n'est dans aucun √©tat mais a d√©j√† √©t√© connect√©
            if not any([is_active, is_draft, waiting_pos is not None, is_queued]) and has_account:
                return {"status": "disconnected", "position": None}

            # D√©terminer le statut en fonction des flags
            if is_active:
                status_info = {
                    "status": "connected",
                    "position": -2
                }
                
                session_ttl = await self.redis.ttl(f'session:{user_id}')
                # Appeler la t√¢che sans self

                
                if session_ttl > 0:
                    status_info["remaining_time"] = session_ttl
                else:
                    if DEBUG :
                        #result = auto_expiration(session_ttl, "active", user_id)
                        result = await auto_expiration(session_ttl, "session", user_id)
                        logger.info(f"T√¢che d'expiration termin√©e: {result}")
                    else:
                        task = auto_expiration.apply_async(args=[session_ttl, "session", user_id])
                        async_result = task
                        while not async_result.ready():
                            await asyncio.sleep(0.1)
                        result = async_result.get()
                        logger.info(f"T√¢che d'expiration termin√©e: {result}")
                        logger.info(f"‚úÖ T√¢che active imm√©diate cr√©√©e pour {user_id}: {task.id}")

                    status_info["remaining_time"] = 0
                    if recall:
                        return await self.get_user_status(user_id, check_slots, recall=False)
                    
            elif is_draft:
                status_info = {
                    "status": "draft",
                    "position": -1
                }

                draft_ttl = await self.redis.ttl(f'draft:{user_id}')

                if draft_ttl > 0:
                    status_info["remaining_time"] = draft_ttl
                else:
                    # Appeler la t√¢che sans self
                    if DEBUG :
                        result = await auto_expiration(draft_ttl, "draft", user_id) 
                        logger.info(f"T√¢che d'expiration termin√©e: {result}")
                    else:
                        task = auto_expiration.apply_async(args=[draft_ttl, "draft", user_id])
                        async_result = task
                        while not async_result.ready():
                            await asyncio.sleep(0.1)
                        result = async_result.get()
                        logger.info(f"T√¢che d'expiration termin√©e: {result}")
                        logger.info(f"‚úÖ T√¢che draft imm√©diate cr√©√©e pour {user_id}: {task.id}")
                    status_info["remaining_time"] = 0
                    # Si le TTL est expir√©, on lance l'auto-expiration et on rappelle get_user_status
                    if recall:
                        return await self.get_user_status(user_id, check_slots, recall=False)
                    
            elif waiting_pos is not None:
                status_info = {
                    "status": "waiting",
                    "position": waiting_pos + 1
                }
                
            else:
                status_info = {
                    "status": "disconnected",
                    "position": None
                }

            # Ajouter un timestamp au statut
            status_info["timestamp"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # Stocker le statut dans la liste et publier
            status_json = json.dumps(status_info)
            last_status = None
            
            # V√©rifier si l'historique des statuts existe d√©j√†
            history_exists = await self.redis.exists(f'status_history:{user_id}')
            if history_exists == 0:
                logger.info(f"Aucun historique de statuts trouv√© pour {user_id}")
            else:
                # R√©cup√©rer le dernier statut stock√©
                last_status_json = await self.redis.lindex(f'status_history:{user_id}', -1)
                if last_status_json:
                    try:
                        last_status = json.loads(last_status_json)
                        logger.info(f"Dernier statut r√©cup√©r√© pour {user_id}: {last_status}")
                        
                        # V√©rifier si on doit checker les slots
                        if check_slots and (status_info["status"] == "waiting" or (last_status.get("status") == "connected" and status_info["status"] != "connected")):
                            await self._check_slots_after_add()
                    except json.JSONDecodeError:
                        logger.error(f"Erreur lors du d√©codage du dernier statut pour {user_id}")
                else:
                    logger.info(f"Aucun statut trouv√© pour {user_id}")
            
            # Ajouter le nouveau statut √† l'historique
            if not last_status or (last_status["status"] != status_info["status"]):
                await self.redis.rpush(f'status_history:{user_id}', status_json)
                await self.redis.publish(f'queue_status:{user_id}', status_json)
            
                # Garder seulement les 100 derniers statuts
                if history_exists:
                    await self.redis.ltrim(f'status_history:{user_id}', -100, -1)
            
            return status_info | {"user_id": user_id}
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration du statut pour {user_id}: {str(e)}")
            error_status = {
                "status": "error",
                "position": None,
                "message": str(e),
                "timestamp": int(time.time())
            }
            error_json = json.dumps(error_status)
            await self.redis.rpush(f'status_history:{user_id}', error_json)
            await self.redis.publish(f'queue_status:{user_id}', error_json)
            return error_status

    async def get_status_messages(self, user_id: str, limit: int = None) -> List[Dict]:
        """R√©cup√®re l'historique des messages de statut pour un utilisateur.
        
        Args:
            user_id: ID de l'utilisateur dont on veut r√©cup√©rer l'historique des statuts.
            limit: Nombre maximum de messages √† r√©cup√©rer (par d√©faut, tous les messages)
        
        Returns:
            List[Dict]: Liste des messages de statut, du plus r√©cent au plus ancien
        """
        try:
            # R√©cup√©rer tous les statuts stock√©s
            if limit is not None:
                messages = await self.redis.lrange(f'status_history:{user_id}', -limit, -1)
            else:
                messages = await self.redis.lrange(f'status_history:{user_id}', 0, -1)
            
            if messages:
                try:
                    # D√©coder les messages JSON
                    status_list = [json.loads(msg) for msg in messages]
                    logger.info(f"{len(status_list)} messages r√©cup√©r√©s pour {user_id}")
                    return status_list
                except Exception as e:
                    logger.error(f"Erreur lors du d√©codage des messages: {str(e)}")
            
            logger.info(f"Aucun message trouv√© pour {user_id}")
            return []
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des messages: {str(e)}")
            return []

    async def get_all_user_statuses(self) -> List[Dict]:
        """R√©cup√®re le statut de tous les utilisateurs dans le syst√®me.
        
        Returns:
            List[Dict]: Une liste de dictionnaires contenant les statuts de tous les utilisateurs.
            Chaque dictionnaire contient:
                - user_id: L'identifiant de l'utilisateur
                - status: Le statut actuel ('waiting', 'draft', 'connected', etc.)
                - position: La position actuelle
                - remaining_time: Le temps restant (pour les statuts draft et connected)
        """
        try:
            all_statuses = []
            
            async with self.redis.pipeline(transaction=True) as pipe:
                # R√©cup√©rer tous les utilisateurs de chaque √©tat
                pipe.smembers('active_users')
                pipe.smembers('draft_users')
                pipe.lrange('waiting_queue', 0, -1)
                active_users, draft_users, waiting_users = await pipe.execute()
                
                # Convertir les sets en listes pour les utilisateurs actifs et en draft
                active_users = list(active_users)
                draft_users = list(draft_users)
                
                logger.debug(f"Utilisateurs trouv√©s - actifs: {len(active_users)}, draft: {len(draft_users)}, en attente: {len(waiting_users)}")
                
                # R√©cup√©rer le statut de chaque utilisateur
                for user_id in active_users:
                    status = await self.get_user_status(user_id)
                    all_statuses.append({
                        "user_id": user_id,
                        **status
                    })
                
                for user_id in draft_users:
                    status = await self.get_user_status(user_id)
                    all_statuses.append({
                        "user_id": user_id,
                        **status
                    })
                
                for user_id in waiting_users:
                    status = await self.get_user_status(user_id)
                    all_statuses.append({
                        "user_id": user_id,
                        **status
                    })
                
            logger.info(f"Total des statuts r√©cup√©r√©s: {len(all_statuses)}")
            return all_statuses
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des statuts: {str(e)}")
            return []

    async def get_timers(self, user_id: str) -> Dict:
        """R√©cup√®re les timers actifs pour un utilisateur."""
        self.logger.info(f"üîç R√©cup√©ration des timers pour {user_id}")
        
        # V√©rifier d'abord le draft
        draft_ttl = await self.redis.ttl(f"draft:{user_id}")
        self.logger.info(f"‚è∞ TTL draft pour {user_id}: {draft_ttl}")
        
        if draft_ttl > 0:
            # L'utilisateur est en draft
            self.logger.info(f"üìù Cr√©ation de la t√¢che draft pour {user_id}")
            task = auto_expiration.delay(draft_ttl, "draft", user_id)
            self.logger.info(f"‚úÖ T√¢che draft cr√©√©e pour {user_id}: {task.id}")
            
            return {
                "timer_type": "draft",
                "ttl": draft_ttl,
                "task_id": task.id,
                "channel": f"timer:channel:{user_id}",
                "status": "active",
                "error": None
            }
        
        # V√©rifier ensuite la session
        session_ttl = await self.redis.ttl(f"session:{user_id}")
        is_active = await self.redis.sismember("active_users", user_id)
        self.logger.info(f"‚è∞ TTL session pour {user_id}: {session_ttl}, actif: {is_active}")
        
        if session_ttl > 0 and is_active:
            # L'utilisateur est en session active
            self.logger.info(f"üìù Cr√©ation de la t√¢che session pour {user_id}")
            task = auto_expiration.delay(session_ttl, "session", user_id)
            self.logger.info(f"‚úÖ T√¢che session cr√©√©e pour {user_id}: {task.id}")
            
            return {
                "timer_type": "session",
                "ttl": session_ttl,
                "task_id": task.id,
                "channel": f"timer:channel:{user_id}",
                "status": "active",
                "error": None,
                "user_id": user_id
            }
        
        # Aucun timer actif
        return {
            "error": "Aucun timer actif pour cet utilisateur",
            "status": "inactive",
            "user_id": user_id
        }

    async def _handle_session_expiration(self, user_id: str):
        """G√®re l'expiration d'une session."""
        async with self.redis.pipeline(transaction=True) as pipe:
            pipe.srem('active_users', user_id)
            pipe.delete(f'session:{user_id}')
            pipe.publish(f'queue_status:{user_id}', json.dumps({
                "status": "disconnected",
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }))
            await pipe.execute()

    async def _handle_draft_expiration(self, user_id: str):
        """G√®re l'expiration d'un draft."""
        async with self.redis.pipeline(transaction=True) as pipe:
            pipe.srem('draft_users', user_id)
            pipe.delete(f'draft:{user_id}')
            pipe.publish(f'queue_status:{user_id}', json.dumps({
                "status": "disconnected",
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }))
            await pipe.execute()

    async def _cleanup_inconsistent_state(self, user_id: str):
        """Nettoie un √©tat incoh√©rent."""
        try:
            logger.warning(f"Nettoyage de l'√©tat incoh√©rent pour {user_id}")
            async with self.redis.pipeline(transaction=True) as pipe:
                pipe.srem('queued_users', user_id)
                pipe.lrem('waiting_queue', 0, user_id)
                pipe.srem('active_users', user_id)
                pipe.srem('draft_users', user_id)
                pipe.delete(f'draft:{user_id}')
                pipe.delete(f'session:{user_id}')
                pipe.delete(f'status_history:{user_id}')
                pipe.delete(f'last_status:{user_id}')
                # Ne pas supprimer de accounts_queue car c'est un historique permanent
                await pipe.execute()
                logger.info(f"√âtat nettoy√© pour {user_id}")
        except Exception as e:
            logger.error(f"Erreur lors du nettoyage de l'√©tat pour {user_id}: {str(e)}")

    async def get_metrics(self) -> dict:
        """Obtient les m√©triques de la file d'attente."""
        async with self.redis.pipeline(transaction=True) as pipe:
            pipe.smembers('active_users')  # R√©cup√©rer tous les utilisateurs actifs
            pipe.lrange('waiting_queue', 0, -1)  # R√©cup√©rer la liste compl√®te
            pipe.scard('accounts_queue')  # Ajouter le nombre total d'utilisateurs enregistr√©s
            pipe.smembers('draft_users')  # R√©cup√©rer les utilisateurs en draft
            results = await pipe.execute()
            
            active_users_set = results[0]
            waiting_users = results[1]
            total_accounts = results[2]
            draft_users = results[3]
            
            # V√©rifier les sessions actives
            async with self.redis.pipeline(transaction=True) as pipe:
                for user_id in active_users_set:
                    pipe.exists(f'session:{user_id}')
                session_results = await pipe.execute()
            
            # Compter uniquement les utilisateurs avec une session valide
            real_active_users = sum(1 for exists in session_results if exists)
            
            # Filtrer les utilisateurs en attente qui ne sont pas en draft
            real_waiting_users = [user for user in waiting_users if user.encode() not in draft_users]
            
            # Convertir les draft_users en liste
            decoded_draft_users = list(draft_users)
            
            return {
                "active_users": real_active_users,
                "waiting_users": len(real_waiting_users),
                "draft_users": decoded_draft_users,
                "total_slots": self.max_active_users,
                "total_accounts": total_accounts
            }

    async def cleanup_session(self, user_id: str) -> bool:
        """Nettoie la session d'un utilisateur.
        
        Args:
            user_id (str): L'identifiant de l'utilisateur
            
        Returns:
            bool: True si le nettoyage a r√©ussi, False sinon
        """
        try:
            logger.debug(f"Nettoyage de la session pour {user_id}")
            async with self.redis.pipeline(transaction=True) as pipe:
                # Supprimer l'utilisateur des ensembles actifs
                pipe.srem('active_users', user_id)
                pipe.delete(f'session:{user_id}')
                await pipe.execute()
                
            logger.info(f"Session nettoy√©e avec succ√®s pour {user_id}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors du nettoyage de la session pour {user_id}: {str(e)}")
            return False

    async def old_auto_expiration(self, ttl, timer_type, user_id):
        """Version asynchrone de auto_expiration qui g√®re la t√¢che Celery."""
        try:
            task = auto_expiration.apply_async(args=[ttl, timer_type, user_id])
            start_time = asyncio.get_event_loop().time()
            
            while not task.ready():
                if asyncio.get_event_loop().time() - start_time > 5:
                    logger.warning(f"Timeout atteint pour la t√¢che {task.id}")
                    break
                await asyncio.sleep(0.1)
            
            result = task.get(timeout=1)
            logger.info(f"T√¢che d'expiration termin√©e: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Erreur lors de l'expiration: {e}")
            return False

    async def cleanup_all(self):
        """Nettoie compl√®tement toutes les files d'attente."""
        try:
            # R√©cup√©rer tous les utilisateurs
            active_users = await self.redis.smembers("active_users")
            draft_users = await self.redis.smembers("draft_users")
            waiting_users = await self.redis.smembers("waiting_users")
            
            # Supprimer les cl√©s sp√©cifiques pour chaque utilisateur
            pipe = self.redis.pipeline()
            for user_id in active_users | draft_users | waiting_users:
                pipe.delete(f"session:{user_id}")
                pipe.delete(f"draft:{user_id}")
                pipe.delete(f"status_history:{user_id}")
                pipe.delete(f"timer:{user_id}")
            
            # Supprimer les sets principaux
            pipe.delete("active_users")
            pipe.delete("draft_users")
            pipe.delete("waiting_users")
            
            # Ex√©cuter toutes les commandes
            await pipe.execute()
            
            return True
        except Exception as e:
            logger.error(f"Erreur lors du nettoyage complet: {e}")
            return False

    async def update_max_users(self, new_max: int) -> bool:
        """Met √† jour le nombre maximum d'utilisateurs actifs.
        
        Args:
            new_max (int): Nouveau nombre maximum d'utilisateurs
            
        Returns:
            bool: True si la mise √† jour a r√©ussi, False sinon
        """
        try:
            if new_max < 1:
                logger.error("Le nombre maximum d'utilisateurs doit √™tre sup√©rieur √† 0")
                return False
            
            self.max_active_users = new_max
            logger.info(f"Nombre maximum d'utilisateurs mis √† jour: {new_max}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de la mise √† jour du nombre maximum d'utilisateurs: {e}")
            return False


async def cleanup_session(user_id: str):
    """Nettoie la session d'un utilisateur."""
    logger.info(f"D√©but de la t√¢che de nettoyage de session pour {user_id}")
    redis = None
    try:
        redis = Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
        # V√©rifier l'√©tat actuel
        async with redis.pipeline(transaction=True) as pipe:
            pipe.sismember('active_users', user_id)
            pipe.exists(f'session:{user_id}')
            results = await pipe.execute()
            
            is_active, has_session = results
            
            # On nettoie si l'utilisateur est actif, m√™me si la session n'existe plus
            if not is_active:
                logger.warning(f"√âtat invalide pour nettoyage: active={is_active}, has_session={has_session}")
                return True
        
        # Effectuer le nettoyage
        async with redis.pipeline(transaction=True) as pipe:
            pipe.srem('active_users', user_id)
            pipe.delete(f'session:{user_id}')
            await pipe.execute()
            
        # Ajouter le nouveau statut √† l'historique
        status_info = {
            "status": "disconnected",
            "position": None,
            "reason": "session_timeout",
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        status_json = json.dumps(status_info)
        await redis.rpush(f'status_history:{user_id}', status_json)
            
        # Publier la notification
        await redis.publish(f'queue_status:{user_id}', status_json)
        
        # V√©rifier l'√©tat final avec les m√©thodes existantes
        expected_state = {
            'in_queue': False,
            'in_waiting': False,
            'in_draft': False,
            'in_active': False,
            'in_accounts_queue': True  # L'utilisateur doit rester dans accounts_queue
        }
        
        # Cr√©er une instance temporaire de QueueManager pour utiliser ses m√©thodes
        queue_manager = QueueManager(redis)
        current_state = await queue_manager._get_current_state(user_id)
        
        if not await queue_manager._verify_queue_state(user_id, expected_state, message="√âtat apr√®s cleanup_session"):
            raise Exception(f"√âtat incoh√©rent apr√®s cleanup_session pour {user_id}. √âtat actuel: {current_state}")
        
        logger.info(f"Session nettoy√©e avec succ√®s pour {user_id}. √âtat final: {current_state}")
        return status_info
        
    except Exception as e:
        logger.error(f"Erreur lors du nettoyage de la session de {user_id}: {str(e)}")
        return False


async def handle_draft_expiration(user_id: str):
    """G√®re l'expiration du draft d'un utilisateur."""
    logger.info(f"D√©but de la t√¢che d'expiration de draft pour {user_id}")
    redis = None
    try:
        redis = Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
        # V√©rifier l'√©tat actuel
        async with redis.pipeline(transaction=True) as pipe:
            pipe.sismember('draft_users', user_id)
            pipe.exists(f'draft:{user_id}')
            pipe.sismember('queued_users', user_id)
            results = await pipe.execute()
            
            is_draft, has_draft, is_queued = results
            
            if not is_draft or is_queued:
                logger.warning(f"√âtat invalide pour expiration: draft={is_draft}, has_draft={has_draft}, queued={is_queued}")
                return True
        
        # Effectuer la transition
        async with redis.pipeline(transaction=True) as pipe:
            pipe.srem('draft_users', user_id)
            pipe.delete(f'draft:{user_id}')
            await pipe.execute()
            
        # Ajouter le nouveau statut √† l'historique
        status_info = {
            "status": "disconnected",
            "position": None,
            "reason": "draft_timeout",
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        status_json = json.dumps(status_info)
        await redis.rpush(f'status_history:{user_id}', status_json)
            
        # Publier la notification
        await redis.publish(f'queue_status:{user_id}', status_json)
        logger.info(f"Draft expir√© avec succ√®s pour {user_id}")
        return status_info
        
    except Exception as e:
        logger.error(f"Erreur lors de l'expiration du draft de {user_id}: {str(e)}")
        return False

@celery.task(name='app.queue_manager.auto_expiration')
async def auto_expiration(ttl, timer_type, user_id):
    """G√®re l'expiration automatique d'une session ou d'un brouillon."""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    

    redis_client = None
    try:
        redis_client = Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
        logging.info(f"D√©marrage de la t√¢che d'expiration {timer_type} pour {user_id}")
        
        if ttl < 0:
            ttl_wait = 0
        else:
            ttl_wait = ttl
        await asyncio.sleep(ttl_wait)
        
        if timer_type == "session":
            is_active = await redis_client.sismember('active_users', user_id)
            if is_active:
                result = await cleanup_session(user_id)
                return {"status": "session_expired", "user_id": user_id, "cleanup_result": result}
        elif timer_type == "draft":
            is_draft = await redis_client.sismember('draft_users', user_id)
            if is_draft:
                result = await handle_draft_expiration(user_id)
                return {"status": "draft_expired", "user_id": user_id, "cleanup_result": result}
                    
        return {"status": "completed", "user_id": user_id, "timer_type": timer_type}

    except Exception as e:
        logging.error(f"‚ùå Erreur dans la t√¢che d'expiration pour {user_id}: {str(e)}")
        return {"status": "error", "user_id": user_id, "error": str(e)}
    finally:
        if redis_client:
            await redis_client.aclose()



# Les autres fonctions restent inchang√©es


@celery.task(name='app.queue_manager.update_timer_channel')
async def update_timer_channel(channel: str, initial_ttl: int, timer_type: str, max_updates: int = 0, task_id: str = None):
    """Met √† jour le canal de timer avec le TTL actuel."""
    redis_client = None
    try:
        redis_client = Redis(
            host=os.getenv('REDIS_HOST', 'localhost'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True
        )
        
        logger.info(f"D√©but de la t√¢che de mise √† jour du timer pour {channel} (TTL initial: {initial_ttl})")
        user_id = channel.split(':')[-1]
        key = f"{timer_type}:{user_id}"
        
        # Obtenir le TTL actuel
        current_ttl = await redis_client.ttl(key)
        if current_ttl <= 0 or current_ttl == -2:
            logger.info(f"TTL expir√© ou invalide pour {key}: {current_ttl}")
            return 0
        
        # Publier le message
        message = {
            'timer_type': timer_type,
            'ttl': current_ttl,
            'updates_left': max_updates if max_updates > 0 else None,
            'task_id': task_id
        }
        await redis_client.publish(channel, json.dumps(message))
        
        # Si on doit continuer les mises √† jour
        if max_updates == 0 or max_updates > 1:
            next_max = max_updates - 1 if max_updates > 0 else 0
            # Programmer la prochaine mise √† jour avec un d√©lai de 1 seconde
            update_timer_channel.apply_async(
                kwargs={
                    'channel': channel,
                    'initial_ttl': initial_ttl,
                    'timer_type': timer_type,
                    'max_updates': next_max,
                    'task_id': task_id
                },
                countdown=1  # D√©lai de 1 seconde
            )
        
        return 1
    except Exception as e:
        logger.error(f"Erreur lors de la mise √† jour du timer {channel}: {str(e)}")
        raise
    finally:
        if redis_client:
            await redis_client.aclose()
            logger.debug(f"Connexion Redis ferm√©e pour {channel}") 